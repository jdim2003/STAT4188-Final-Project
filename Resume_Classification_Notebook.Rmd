---
title: "Resume Dataset"
output: pdf_document
date: "2024-12-02"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{python}
import pandas as pd
import re
import matplotlib.pyplot as plt
from collections import Counter
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder


file_path = "/Users/jessedimarzo/Downloads/Resume.csv"

resume_data = pd.read_csv(file_path)

resume_data.head(5)
```
```{python}
def clean_text(text):
    text = text.lower()
    text = re.sub(r'[^a-z\s]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

# Convert text to lowercase, remove special characters, numbers, and punctuation, remove extra whitespace, using the built in python library re. This is not something we discussed in class, but it is very helpful since we are dealing with strings in this dataset.
```

```{python}
resume_data['Cleaned_Resume_str'] = resume_data['Resume_str'].apply(clean_text)
# Apply the created cleaning function to the Resume_str column in the dataset
```



```{python}
print(resume_data['ID'].is_unique)
# Just to confirm that the ID is a unique identifier, which the output of "True" confirmed. 
# The ID column is unnecessary for the analysis and modeling we will be performing, and thus will be removed at this stage in the cleaning process.
```

```{python}
# Drop the ID column as stated
resume_data = resume_data.drop(columns=['ID'])

# To confirm the column is removed
print(resume_data.head())
```

Exploratory Data Analysis (EDA)
```{python}
print(category_counts)
```
The above code provides the count of each job category present in the dataset. The purpose of this is to check for imbalances in the data, as this could lead to biased classification models, which could perform poorly on underrepresented categories. 

From the output, the top categories are INFORMATION-TECHNOLOGY and BUSINESS-DEVELOPMENT, both containing 120 resumes. Many of the other categories are right below 120, with the top 15 categories(by count) all within 10 resumes of the top two.

There are a few underrepresented categories, specifically in AGRICULTURE (63 resumes), AUTOMOBILE (36 resumes), and BPO (22 resumes). Clearly, there is a significant imbalance in these categories compared to the others, which could affect classification model performance. To combat this class imbalance, techniques such as stratified train-test splits will ensure that all categories are represented proportionally.  

The imbalances are shown in the following bar chart:

```{python}
category_counts = resume_data['Category'].value_counts()
plt.figure(figsize=(16, 8))
plt.bar(category_counts.index, category_counts.values)
plt.title('Distribution of Resumes by Job Category')
plt.xlabel('Job Category')
plt.ylabel('Number of Resumes')
plt.xticks(rotation=90)
plt.subplots_adjust(bottom=0.5)
plt.show()
```
```{python}
resume_data['Text_Length'] = resume_data['Cleaned_Resume_str'].apply(len)

plt.figure(figsize=(9, 4))
plt.hist(resume_data['Text_Length'], bins=20, edgecolor='black')
plt.title('Distribution of Resume Text Lengths', fontsize=14)
plt.xlabel('Text Length (characters)', fontsize=12)
plt.ylabel('Frequency', fontsize=12)

plt.xticks(rotation=45, ha='right')

plt.tight_layout()
plt.show()
```

```{python}
it_resumes = resume_data[resume_data['Category'] == 'INFORMATION-TECHNOLOGY']
common_words = Counter(" ".join(it_resumes['Cleaned_Resume_str']).split()).most_common(20)
print(common_words)
```

```{python}
aviation_resumes = resume_data[resume_data['Category'] == 'AVIATION']
common_words1 = Counter(" ".join(aviation_resumes['Cleaned_Resume_str']).split()).most_common(30)
print(common_words1)
```
```{python}
vectorizer = TfidfVectorizer(max_features=5000)
tfidf_matrix = vectorizer.fit_transform(resume_data['Cleaned_Resume_str'])
```
```{python}
label_encoder = LabelEncoder()
resume_data['Category_Label'] = label_encoder.fit_transform(resume_data['Category'])
```


